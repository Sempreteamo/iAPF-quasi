library(mvtnorm)
library(MASS)
library(FKF)

##parameters
start = proc.time()
set.seed(1)
Num <- 1000 #total number of particles
N <- vector()
N[1] <- Num
Time = 200
specific = Time #The specific time that we want to compare the distributions
L = 40 #lag
A = 0.42
B = 1
C = 1
D = 1
d = 1
k <- 5
tau <- 0.5
X_true <- vector()
obs <- vector()
kappa = 0.5
tau <- 0.5
dt <- ct <- 0
Tt <- as.matrix(A)
P0 <- Zt <- Ht <- Gt <- as.matrix(1)
a0 <- 0
index <- 1
psi_final <- matrix(NA, nrow = Time + 3*L/4, ncol = 2)

Obs <- function(){
  X_true[1] <- rnorm(1)   
  for(t in 2:(Time + L/2)){  #observations
    X_true[t] <- rnorm(1) + A*X_true[t-1] 
  }
  return(rnorm(Time + L/2) + X_true)
}
obs <- Obs()

#if we want to repeat the experiment, then start from here
X <- matrix(NA, Time + L/2, Num)
X_ <- matrix(NA, Time + L/2, Num)
w <- matrix(NA, Time + L/2, Num)
Z = 0
Z_apf <- vector()

#the mean, variance of the smoothing distribution and normalizing constant
fkf.obj <- fkf(a0, P0, dt, ct, Tt, Zt, Ht, Gt, yt = t(obs))
fks.obj <- fks(fkf.obj)
fkf.obj_Z <- fkf(a0, P0, dt, ct, Tt, Zt, Ht, Gt, yt = t(obs[1:Time]))$logLik

Smoothing <- function(specific_time){
  fks_mean <- fks.obj$ahatt[,specific_time]
  fks_var <- fks.obj$Vt[,,specific_time]
  return(list(fks_mean, fks_var))
}

##Start our iAPF-quasi algorithm
n <- L

source('iapf_only_controlled_new_ed2.R')


####Initialization####
iAPF1 <- function(time_step) {
  #initialization for time t = 1...L to obtain psi1, w1, X1
  output <- Init(time_step) 
  X <- output[[1]] 
  w <- output[[2]]
  psi <- output[[3]]
  
  #choose psi from 1 to 3L/4
  psi_final <- psi[complete.cases(psi), ][1:(3*L/4),]
  
  #Iteration
  #obtain 
  if(L < Time){
    for(time_step in seq(2*L,Time,L)){
      
      #I didn't include any resampling in this step
      #Run iAPF with the initial distribution we defined 
      
      output <- init_APF(time_step, w, X)
      X_apf <- output[[1]]
      w_apf <- output[[2]]
      Z_apf <- output[[3]]
      
      output2 <- psi_APF(time_step, X_apf, Z_apf, w, X)
      
      #smoothing particles
      X <- output2[[1]]
      w <- output2[[2]]
      psi <- output2[[3]]
      gap_matrix <- matrix(NA, nrow = L/2, ncol = 2)
      
      #take psi from kL+L/4+1 to kL+3L/4+1
      psi_final <- rbind(psi_final, gap_matrix, psi[complete.cases(psi), ][(L/4 + 1):(3*L/4),])
    }  
  }
  return(psi_final)
}

psi_final <- iAPF1(n)
####the second layer of iAPF from t=1 to L to obtain psi####

n <- L/2
#iAPF2 <- function(psi_final, time_step) {
  #t = 1, . . . , L/2 to obtain X2, w2 and psi2
 # psi_final <- psi_final
  time_step <- n
  L <- L/2
  output <- Init(time_step) 
  X <- output[[1]] 
  w <- output[[2]]
  psi <- output[[3]]    
  
  L <- 2*L
  ####Algorithm####
  if(L < Time){
    #start from L/2 to 3L/2 to obtain psi2
    count = 0
    for(time_step in seq(3*L/2,Time+L/2,L)){
      #I didn't include any resampling in this step
      #Run iAPF with the initial distribution we defined 
      
      output <- init_APF(time_step, w, X)
      X_apf <- output[[1]]
      w_apf <- output[[2]]
      Z_apf <- output[[3]]
      
      output2 <- psi_APF(time_step, X_apf, Z_apf, w, X)
      
      #smoothing particles
      X <- output2[[1]]
      w <- output2[[2]]
      psi <- output2[[3]]
      
      if(time_step != Time+L/2){
        psi_final[(3*L/4+1+count*L):(3*L/4+count*L+ L/2),] <- psi[complete.cases(psi), ][(L/4 + 1):(3*L/4),]
      }else{
        psi_final <- rbind(psi_final, psi[complete.cases(psi), ][(L/4 + 1):(L/2),])
      }
      
      count = count + 1
    }  
  }
#  return(psi_final)
#}

#psi_final <- iAPF2(psi_final, n)

####psi-APF####
#purely smoothing particles and normalizing constant
smoothing_APF <- function(psi_pa){ 
  #l >= 2
  X_apf <- matrix(NA, Time, Num)
  w_apf <- matrix(NA, Time, Num)
  
  Z_apf <- 0
  
  #when n = kL, we use the new mu.tilda to initialize particles
  
  X_apf[1,] <- mu_aux(psi_pa, 1, N, 1) 
  for(i in 1:Num){
    w_apf[1,i] <- log(g_aux_smoo(obs[1], X_apf[1,i],1, psi_pa, Time)) 
  }
  
  for(t in 2:Time){
    
    if(ESS(t,w_apf, is.log = TRUE) <= kappa*Num){
      
      mx <- max(w_apf[t-1,])
      w_ <- exp(w_apf[t-1,1:Num]-mx)/sum(exp(w_apf[t-1, 1:Num] - mx))
      Z_apf = Z_apf + log(mean(exp(w_apf[t-1,]-mx))) + mx
      mix <- sample(1:Num,Num, replace = TRUE, prob = w_)
      X_apf <- X_apf[, mix]
      
      for(i in 1:Num){
        #filtering particles
        X_apf[t,i] <- f_aux(X_apf[t-1, i], psi_pa, t)
        w_apf[t,i] <- log(g_aux_smoo(obs[t], X_apf[t,i], t, psi_pa, Time))  
        
      }
    }else{
      
      for(i in 1:Num){
        #filtering particles
        X_apf[t,i] <- f_aux(X_apf[t-1,i], psi_pa, t) 
        w_apf[t,i] <- w_apf[t-1,i] + log(g_aux_smoo(obs[t], X_apf[t,i], t, psi_pa, Time))
      }
    }
    
  }
  
  mx <- max(w_apf[Time, 1:Num])
  Z_apf <- Z_apf + log(mean(exp(w_apf[Time, 1:Num]-mx))) + mx
  
  return(list(X_apf, w_apf, Z_apf))
}
  
output2 <- smoothing_APF(psi_final)
X <- output2[[1]]
w <- output2[[2]]
Z <- output2[[3]]

mx <- max(w[Time,]) 
#Z <- Z + log(mean(exp(w[Time,]-mx))) + mx
mx <- max(w[specific,]) 
w_ <- exp(w[specific,]-mx)/sum(exp(w[specific,] - mx))

#Calculation of the mean and variance of empirical distribution
#Here 'weighted_mean' is the empirical mean, 'variance' is the empirical variance
Empirical <- function(specific_time){
  weighted_mean <- sum(w_*X[specific_time,])
  s_mean <- sum(w_*X[specific_time,]^2)
  variance <- s_mean - weighted_mean^2
  return(list(weighted_mean, variance))
}
output_e <- Empirical(specific)
output_s <- Smoothing(specific)
weighted_mean <- output_e[[1]]
variance <- output_e[[2]]
fks_mean <- output_s[[1]]
fks_var <- output_s[[2]]

#empirical distribution function
#the equation of dKS(F, G) below is in the notes

dKS <- function(specific_time) {
  d <- vector()
  order <- order(X[specific_time,])
  X[specific_time,] <- sort(X[specific_time,])
  w_ <- w_[order]
  cumsum_w <- cumsum(w_)
  f <- pnorm(X[specific_time,], mean = fks_mean, sd = sqrt(fks_var)) 
  d <- abs(f - cumsum_w)
  return(max(d))
}

KS_distance <- dKS(specific)
normalizing_c <- exp(Z-fkf.obj_Z)

#Note that the normalizing constant here is just the values calculated within each 
#block from n-L+1 to n.It's not the real normalizing constant Z. 
#It should be adjusted to get the value. 

proc.time() - start
