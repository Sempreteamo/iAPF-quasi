library(mvtnorm)
library(MASS)
library(FKF)
library(profvis)
library(mvnfast)

##parameters
start = proc.time()
set.seed(123)
Num <- 200 #total number of particles
N <- vector()
N[1] <- Num
Time = 200
Lag = 16 #lag can be any integers <= Time which is divided by Time
alpha = 0.42
d = 5
k <- 5
tau <- 0.5
kappa = 0.5
A <- matrix(nrow = d, ncol = d)
for (i in 1:d){
  for (j in 1:d){
    A[i,j] = alpha^(abs(i-j) + 1)
  }
}
B = C = D = diag(1, nrow = d, ncol = d)
X_true <-  matrix(0, nrow = Time, ncol = d )
obs <-  matrix(0, nrow = Time, ncol = d )
dt <- ct <- matrix(0, d, 1)
Tt <- A
P0 <- Zt <- Ht <- Gt <- diag(1, d, d)
a0 <- rep(0, d)
index <- 1
psi_final <- matrix(NA, nrow = Time, ncol = 2*d)
MH_distance <- vector()
KS_distance <- vector()

Obs <- function(){
  #set.seed(123)
  X_true[1,] <- rnorm(d)     
  for(t in 2:Time){ 
    #set.seed(123)#observations
    X_true[t,] <- rnorm(d) + A%*%X_true[t-1,]  #t(rmvn(d) + A%*%x)
  }
  #set.seed(123)
  return(matrix(rnorm(Time*d, X_true, 1), ncol = d))
}
obs <- Obs()

X <- array(NA, dim = c(Time, Num, d))
X_ <- array(NA, dim = c(Time, Num, d))
w <- matrix(NA, Time, Num)
Z = 0
Z_apf <- vector()

fkf.obj <- fkf(a0, P0, dt, ct, Tt, Zt, Ht, Gt, yt = t(obs))
fks.obj <- fks(fkf.obj)
fkf.obj_Z <- fkf(a0, P0, dt, ct, Tt, Zt, Ht, Gt, yt = t(obs))$logLik #???

Smoothing <- function(specific_time){
  fks_mean <- fks.obj$ahatt[,specific_time]
  fks_cov <- fks.obj$Vt[,,specific_time]
  return(list(fks_mean, fks_cov))
}

source('iapf_nd.R')


#purely smoothing particles and normalizing constant
smoothing_APF <- function(psi_pa, N, Time){ 
  #l >= 2
  X <- array(NA, dim = c(Time, N[l], d))
  w <- matrix(NA, Time, N[l])
  Z[l] <- 0
  
  X[1, ,] <- mu_aux(psi_pa, l)  #particles
  
  for(i in 1:N[l]){
    w[1,i] <- log(g_aux(obs[1,], X[1,i,],1, psi_pa)) #weights g(obs[1,], X[1,i,])*psi_tilda(X[1,i,], psi_pa, 2)  
  }
  #re=0
  
  #t=2:T
  #2. conditional sample
  for(t in 2:Time){
    
    #print(t)
    
    #a)
    
    if(ESS(t,w, is.log=TRUE) <= kappa*N[l]){
      mx <- max(w[t-1,  ])
      Z[l] <- Z[l] + log(mean(exp(w[t-1,  ]-mx))) + mx	
      #re = re+1
      #w_ <- exp(w[t-1, ]-mx)/sum(exp(w[t-1, ]-mx))   #each t
      #mix <- sample(1:N[l],N[l], replace = TRUE, prob = w_)
      mix <- residual(t, w)
      X_apf <- X_apf[, mix,, drop = FALSE]
      
      for(i in 1:N[l]){
        X[t,i,] <- f_aux(X[t-1, i,], psi_pa, t)
        w[t,i] <- log(g_aux(obs[t,], X[t,i,], t, psi_pa))  
      }
    }else{
      
      #b)
      for(i in 1:N[l]){
        
        X[t,i,] <- f_aux(X[t-1,i,],psi_pa, t) 
        w[t,i] <- w[t-1,i] + log(g_aux(obs[t,], X[t,i,],t, psi_pa))  
      }
    }
    
  }
  mx <- max(w[t,])
  Z[l] <- Z[l] + log(mean(exp(w[t,]-mx))) + mx
  
  #when n = kL, we use the new mu.tilda to initialize particles
  
  return(list(X, w, Z[l], re))
}

output2 <- smoothing_APF(psi_pa, N, Time)
X <- output2[[1]]
w <- output2[[2]]
Z <- output2[[3]]
re <- output2[[4]] #above are not the same

mx <- max(w[Time,]) 
w_ <- exp(w[Time,]-mx)/sum(exp(w[Time,] - mx))

#Mahalanobis distance
for(specific in 1:Time){
  weighted_mean <- colSums(w_*X[specific,,])
  output_s <- Smoothing(specific)
  fks_mean <- output_s[[1]]
  fks_cov <- output_s[[2]]
  MH_distance[specific] <- mahalanobis(weighted_mean, fks_mean, fks_cov)/d
}

plot(MH_distance)
normalizing_c <- exp(Z-fkf.obj_Z)
normalizing_c
title('N200d5')

#Calculation of the mean and variance of empirical distribution
#Here 'weighted_mean' is the empirical mean, 'variance' is the empirical variance
Empirical <- function(X, w_, specific_time){
  weighted_mean <- sum(w_*X[specific_time,])
  s_mean <- sum(w_*X[specific_time,]^2)
  variance <- s_mean - weighted_mean^2
  return(list(weighted_mean, variance))
}

#output_e <- Empirical(X, w_, specific)
#weighted_mean <- output_e[[1]]
#variance <- output_e[[2]]
#empirical distribution function
#the equation of dKS(F, G) below is in the notes

dKS <- function(X, w_, specific_time) {
  output_s <- Smoothing(specific_time)
  fks_mean <- output_s[[1]]
  fks_var <- output_s[[2]]
  
  #the replacement of the weights and particles matrices
  X_ <- X
  w_c <- w_
  
  d <- vector()
  order <- order(X[specific_time,,])
  X_[specific_time,,] <- sort(X[specific_time,,])
  w_c <- w_[order]
  cumsum_w <- cumsum(w_c)
  f <- pnorm(X_[specific_time,,], mean = fks_mean, sd = sqrt(fks_var)) 
  d <- abs(f - cumsum_w)
  return(max(d))
}.

#KS_distance <- dKS(X, w_, specific)
normalizing_c <- exp(Z-fkf.obj_Z)
#KS_distance_start <- dKS(X, w_, specific1)

for(specific in 1:Time){
  KS_distance[specific] <- dKS(X, w_, specific)
}
